import os
import torch
import json
import pandas as pd
import argparse
from params import Params
from utils import load_all_data, set_seed, evaluate, evaluate_f1, load_tfidf_matrices
from Trainer import Trainer

DATASETS = [
    "ag_news_data",
    "mr_data",
    "ohsumed_data",
    "twitter_data",
    "snippets_data",
    "tagmynews_data"
]
BASE_DIR = "/root/autodl-tmp/zs/My_Model/data" 

summary_results = []

def run_dataset(dataset_name):
    print(f"\nğŸš€ æ­£åœ¨è®­ç»ƒæ•°æ®é›†ï¼š{dataset_name}")
    params = Params()
    set_seed(params.seed)
    params.data_dir = os.path.join(BASE_DIR, dataset_name)
    params.save_model_path = os.path.join(params.data_dir, "best_model.pt")
    
    # # ==== åŠ è½½æœ€ä½³è¶…å‚ ====
    # best_param_path = f"best_params_{dataset_name}.json"
    # if os.path.exists(best_param_path):
    #     with open(best_param_path, "r") as f:
    #         best_params = json.load(f)
    #     for k, v in best_params.items():
    #         setattr(params, k, v)
    #     print(f"âœ… å·²åŠ è½½æœ€ä¼˜å‚æ•°: {best_param_path}")
    # else:
    #     print(f"âš ï¸ æœªæ‰¾åˆ° {best_param_path}ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°ã€‚")

    # âœ… åŠ è½½æ•°æ®
    print("ğŸ“¦ åŠ è½½å›¾ç»“æ„ä¸ç‰¹å¾æ•°æ®...")

    # === MODIFIED: åªåŠ è½½word/pos/entityç‰¹å¾å’ŒåŒæ„é‚»æ¥ ===
    h_dict, adj_dicts, labels, train_idx, val_idx, test_idx, augmented = load_all_data(params)
    
    # === æ–°å¢: åŠ è½½TF-IDFï¼ˆæˆ–æ± åŒ–æƒé‡ï¼‰çŸ©é˜µ ===
    tfidf_word, tfidf_pos, tfidf_entity = load_tfidf_matrices(params.data_dir)
    print("âœ… æ•°æ®åŠ è½½å®Œæ¯•")

    params.num_classes = len(set(labels.tolist()))

    print("word_emb shape:", h_dict[0].shape)
    print("pos_emb shape:", h_dict[1].shape)
    print("entity_emb shape:", h_dict[2].shape)

    # === MODIFIED: Trainerå’Œæ¨¡å‹forwardè¦æ¥æ”¶tfidfæ± åŒ–çŸ©é˜µ ===
    trainer = Trainer(params, h_dict, adj_dicts, labels, augmented, train_idx, val_idx, test_idx,
    tfidf_word, tfidf_pos, tfidf_entity)
    trainer.train()
    trainer.test()

    # âœ… ä¿å­˜æ¨¡å‹
    torch.save(trainer.model.state_dict(), params.save_model_path)
    print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜ä¸º {params.save_model_path}")

    # âœ… ä¿å­˜è®­ç»ƒæ—¥å¿—
    try:
        metrics = {
            'epoch': list(range(len(trainer.train_acc_log))),
            'train_acc': trainer.train_acc_log,
            'val_acc': trainer.val_acc_log,
            'train_f1': trainer.train_f1_log,
            'val_f1': trainer.val_f1_log  
        }
        log_path = os.path.join(params.data_dir, "train_log.csv")
        df = pd.DataFrame(metrics)
        df.to_csv(log_path, index=False)
        print(f"ğŸ“ˆ æ—¥å¿—ä¿å­˜ä¸º {log_path}")
    except Exception as e:
        print("âš ï¸ æ—¥å¿—ä¿å­˜å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰ï¼š", e)

    # âœ… ä¿å­˜éªŒè¯é›† & æµ‹è¯•é›† F1 åˆ†æ•°
    try:
        val_logits, _ = trainer.model(
            h_dict, adj_dicts, tfidf_word, tfidf_pos, tfidf_entity, return_feats=True
        )
        val_f1_macro, val_f1_micro = evaluate_f1(val_logits, labels, val_idx)
        val_acc = evaluate(val_logits, labels, val_idx)
        
        test_logits, _ = trainer.model(
            h_dict, adj_dicts, tfidf_word, tfidf_pos, tfidf_entity, return_feats=True
        )
        test_f1_macro, test_f1_micro = evaluate_f1(test_logits, labels, test_idx)
        test_acc = evaluate(test_logits, labels, test_idx)
        
        # æ–°å¢æ›´è¯¦ç»†çš„é¢„æµ‹åˆ†å¸ƒ/ç½®ä¿¡åº¦
        if hasattr(val_logits, "softmax"):
            with torch.no_grad():
                probs = torch.softmax(val_logits, dim=1)
                print("[DEBUG] éªŒè¯é›† logits softmax åˆ†å¸ƒå‰5:", probs[:5].detach().cpu().numpy())
                # [çº¦è¡Œ 115] æ£€æŸ¥å„é›†é¢„æµ‹åˆ†å¸ƒ
                print("[DEBUG] val_pred_counts:", torch.argmax(val_logits, dim=1)[val_idx].bincount())
                print("[DEBUG] test_pred_counts:", torch.argmax(test_logits, dim=1)[test_idx].bincount())
        
        summary = {
            "dataset": dataset_name,
            "val_acc": round(val_acc, 4),
            "val_f1_macro": round(val_f1_macro, 4),
            "val_f1_micro": round(val_f1_micro, 4),
            "test_acc": round(test_acc, 4),
            "test_f1_macro": round(test_f1_macro, 4),
            "test_f1_micro": round(test_f1_micro, 4)
        }

        # ä¿å­˜å•ä¸ªæ•°æ®é›† JSON
        summary_path = os.path.join(params.data_dir, "eval_summary.json")
        with open(summary_path, "w") as f:
            json.dump(summary, f, indent=4)

        print(f"ğŸ“Š F1 ç»“æœä¿å­˜ä¸º {summary_path}")

        # åŠ å…¥å…¨å±€ summary_results åˆ—è¡¨
        summary_results.append(summary)

    except Exception as e:
        print("âš ï¸ F1 è¯„ä¼°æŒ‡æ ‡ä¿å­˜å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰ï¼š", e)
    

if __name__ == "__main__":
    for ds in DATASETS:
        run_dataset(ds)

    # âœ… ä¿å­˜æ‰€æœ‰æ•°æ®é›†æ±‡æ€»çš„ summary.csv
    try:
        df = pd.DataFrame(summary_results)
        df.to_csv("summary_all_results.csv", index=False)
        print("ğŸ“Š æ‰€æœ‰æ•°æ®é›†æ±‡æ€» F1 å·²ä¿å­˜ä¸º summary_all_results.csv")
    except Exception as e:
        print("âš ï¸ æ±‡æ€»è¡¨ä¿å­˜å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰ï¼š", e)
